import streamlit as st
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.datasets import fetch_openml
from sklearn.model_selection import train_test_split
from sklearn.cluster import KMeans, DBSCAN
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score
from streamlit_drawable_canvas import st_canvas
from PIL import Image
import mlflow
import os
import random
from datetime import datetime

# T·∫£i d·ªØ li·ªáu MNIST t·ª´ OpenML
@st.cache_data
def load_mnist_data():
    X, y = fetch_openml('mnist_784', version=1, return_X_y=True, as_frame=False)
    X = X / 255.0  # Chu·∫©n h√≥a ngay khi t·∫£i
    return X, y.astype(int)

# Tab hi·ªÉn th·ªã d·ªØ li·ªáu
def data_processing():
    st.header("üìò D·ªØ Li·ªáu MNIST")
    X, y = load_mnist_data()
    
    st.write("""
        **Th√¥ng tin t·∫≠p d·ªØ li·ªáu MNIST:**
        - T·ªïng s·ªë m·∫´u: {}
        - K√≠ch th∆∞·ªõc m·ªói ·∫£nh: 28 √ó 28 pixels (784 ƒë·∫∑c tr∆∞ng)
        - S·ªë l·ªõp: 10 (ch·ªØ s·ªë t·ª´ 0-9)
    """.format(X.shape[0]))

    st.subheader("M·ªôt s·ªë h√¨nh ·∫£nh m·∫´u")
    n_samples = 5
    fig, axes = plt.subplots(1, n_samples, figsize=(10, 3))
    indices = np.random.choice(X.shape[0], n_samples, replace=False)
    for i, idx in enumerate(indices):
        axes[i].imshow(X[idx].reshape(28, 28), cmap='gray')
        axes[i].set_title(f"Label: {y[idx]}")
        axes[i].axis("off")
    st.pyplot(fig)

# Tab chia d·ªØ li·ªáu
def split_data():
    st.title("üìå Chia d·ªØ li·ªáu Train/Test")
    X, y = load_mnist_data()
    total_samples = X.shape[0]

    if "data_split_done" not in st.session_state:
        st.session_state.data_split_done = False

    num_samples = st.slider("Ch·ªçn s·ªë l∆∞·ª£ng ·∫£nh ƒë·ªÉ train:", 1000, total_samples, 10000)
    test_size_percent = st.slider("Ch·ªçn t·ª∑ l·ªá test (%):", 10, 50, 20)  # ƒê·ªïi sang ph·∫ßn trƒÉm
    test_size = test_size_percent / 100  # Chuy·ªÉn ƒë·ªïi sang d·∫°ng th·∫≠p ph√¢n ƒë·ªÉ s·ª≠ d·ª•ng trong train_test_split

    if st.button("‚úÖ X√°c nh·∫≠n & L∆∞u") and not st.session_state.data_split_done:
        st.session_state.data_split_done = True
        X_selected, _, y_selected, _ = train_test_split(X, y, train_size=num_samples, random_state=42)
        X_train, X_test, y_train, y_test = train_test_split(X_selected, y_selected, test_size=test_size, random_state=42)

        st.session_state.total_samples = num_samples
        st.session_state.X_train = X_train
        st.session_state.X_test = X_test
        st.session_state.y_train = y_train
        st.session_state.y_test = y_test
        st.session_state.train_size = X_train.shape[0]
        st.session_state.test_size = X_test.shape[0]

        summary_df = pd.DataFrame({
            "T·∫≠p d·ªØ li·ªáu": ["Train", "Test"],
            "S·ªë l∆∞·ª£ng m·∫´u": [X_train.shape[0], X_test.shape[0]]
        })
        st.success(f"üîπ D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c chia: Train ({len(X_train)}), Test ({len(X_test)})")
        st.table(summary_df)

    elif st.session_state.data_split_done:
        st.info("‚úÖ D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c chia, kh√¥ng c·∫ßn ch·∫°y l·∫°i.")
# Tab hu·∫•n luy·ªán v√† ph√¢n c·ª•m

import streamlit as st
import numpy as np
from sklearn.cluster import KMeans, DBSCAN
from sklearn.metrics import accuracy_score
from sklearn.model_selection import cross_val_score
import mlflow
import mlflow.sklearn
import os

import streamlit as st
import numpy as np
from sklearn.cluster import KMeans, DBSCAN
from sklearn.decomposition import PCA
from sklearn.metrics import accuracy_score
from scipy.stats import mode
import mlflow
import mlflow.sklearn
import os

def train_evaluate():
    st.header("‚öôÔ∏è Ch·ªçn m√¥ h√¨nh & Hu·∫•n luy·ªán")
    
    if "X_train" not in st.session_state:
        st.error("‚ö†Ô∏è Ch∆∞a c√≥ d·ªØ li·ªáu! H√£y chia d·ªØ li·ªáu tr∆∞·ªõc.")
        return

    X_train = st.session_state.X_train.reshape(-1, 28 * 28) / 255.0
    X_test = st.session_state.X_test.reshape(-1, 28 * 28) / 255.0
    y_train = st.session_state.y_train
    y_test = st.session_state.y_test

    model_choice = st.selectbox("Ch·ªçn m√¥ h√¨nh:", ["K-Means", "DBSCAN"])
    
    if model_choice == "K-Means":
        st.markdown("""
        - **K-Means**: Thu·∫≠t to√°n ph√¢n c·ª•m kh√¥ng gi√°m s√°t, chia d·ªØ li·ªáu th√†nh K nh√≥m d·ª±a tr√™n kho·∫£ng c√°ch Euclidean.
        - **Tham s·ªë c·∫ßn ch·ªçn:**  
            - **S·ªë c·ª•m (K)**: S·ªë nh√≥m mong mu·ªën (th∆∞·ªùng ch·ªçn b·∫±ng s·ªë l·ªõp trong MNIST, v√≠ d·ª• 10).
        """)
        n_clusters = st.slider("S·ªë c·ª•m (K):", 2, 20, 10)
        model = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
        params = {"n_clusters": n_clusters}
    else:  # DBSCAN
        st.markdown("""
        - **DBSCAN**: Thu·∫≠t to√°n ph√¢n c·ª•m d·ª±a tr√™n m·∫≠t ƒë·ªô, t·ª± ƒë·ªông x√°c ƒë·ªãnh s·ªë c·ª•m d·ª±a tr√™n ph√¢n b·ªë d·ªØ li·ªáu.
        - **Tham s·ªë c·∫ßn ch·ªçn:**
            - **eps**: B√°n k√≠nh l√¢n c·∫≠n ƒë·ªÉ x√°c ƒë·ªãnh ƒëi·ªÉm l√°ng gi·ªÅng.
            - **min_samples**: S·ªë ƒëi·ªÉm t·ªëi thi·ªÉu ƒë·ªÉ t·∫°o th√†nh c·ª•m.
        """)
        eps = st.slider("B√°n k√≠nh l√¢n c·∫≠n (eps):", 0.1, 10.0, 0.5, step=0.1)
        min_samples = st.slider("S·ªë ƒëi·ªÉm t·ªëi thi·ªÉu:", 2, 20, 5)
        model = DBSCAN(eps=eps, min_samples=min_samples)
        params = {"eps": eps, "min_samples": min_samples}

    run_name = st.text_input("üîπ Nh·∫≠p t√™n Run:", f"{model_choice}_Run")
    st.session_state["run_name"] = run_name if run_name else "default_run"
    
    if st.button("üöÄ Hu·∫•n luy·ªán m√¥ h√¨nh"):
        st.write(f"‚è≥ ƒêang hu·∫•n luy·ªán m√¥ h√¨nh '{model_choice}'...")
        with st.spinner("ƒêang x·ª≠ l√Ω d·ªØ li·ªáu v√† hu·∫•n luy·ªán..."):
            # Gi·∫£m chi·ªÅu d·ªØ li·ªáu b·∫±ng PCA tr∆∞·ªõc khi hu·∫•n luy·ªán
            pca = PCA(n_components=2)
            X_train_pca = pca.fit_transform(X_train)
            X_test_pca = pca.transform(X_test)

            # L∆∞u PCA v√†o session_state ƒë·ªÉ d√πng trong demo
            st.session_state["pca"] = pca

            # Hu·∫•n luy·ªán m√¥ h√¨nh
            model.fit(X_train_pca)
            labels_train = model.labels_ if model_choice == "K-Means" else model.fit_predict(X_train_pca)
            
            # ƒê√°nh gi√° tr√™n t·∫≠p train
            if model_choice == "K-Means":
                label_mapping = {}
                for i in range(n_clusters):
                    mask = labels_train == i
                    if np.sum(mask) > 0:
                        most_common = mode(y_train[mask], keepdims=True).mode[0]
                        label_mapping[i] = most_common
                predicted_labels = np.array([label_mapping.get(label, -1) for label in labels_train])
                train_accuracy = accuracy_score(y_train.astype(int), predicted_labels)
                st.success(f"‚úÖ ƒê·ªô ch√≠nh x√°c tr√™n t·∫≠p train: {train_accuracy:.4f}")
            else:  # DBSCAN
                n_clusters_train = len(set(labels_train)) - (1 if -1 in labels_train else 0)
                st.success(f"‚úÖ S·ªë c·ª•m tr√™n t·∫≠p train: {n_clusters_train}")

            # ƒê√°nh gi√° tr√™n t·∫≠p test
            labels_test = model.predict(X_test_pca) if model_choice == "K-Means" else model.fit_predict(X_test_pca)
            if model_choice == "K-Means":
                test_predicted_labels = np.array([label_mapping.get(label, -1) for label in labels_test])
                test_accuracy = accuracy_score(y_test.astype(int), test_predicted_labels)
                st.success(f"‚úÖ ƒê·ªô ch√≠nh x√°c tr√™n t·∫≠p test: {test_accuracy:.4f}")
            else:  # DBSCAN
                n_clusters_test = len(set(labels_test)) - (1 if -1 in labels_test else 0)
                st.success(f"‚úÖ S·ªë c·ª•m tr√™n t·∫≠p test: {n_clusters_test}")

            # üéØ **T√≠ch h·ª£p MLflow**
            try:
                with mlflow.start_run(run_name=f"Train_{st.session_state['run_name']}") as run:
                    run_id = run.info.run_id
                    
                    # Log c√°c tham s·ªë
                    mlflow.log_params({"model_type": model_choice, **params})
                    mlflow.log_param("train_size", X_train.shape[0])
                    mlflow.log_param("test_size", X_test.shape[0])
                    mlflow.log_param("total_samples", st.session_state.total_samples)
                    mlflow.log_param("pca_components", 2)

                    # L∆∞u d·ªØ li·ªáu t·∫°m th·ªùi v√† log artifact
                    os.makedirs("mlflow_artifactsb5", exist_ok=True)
                    dataset_path = "mlflow_artifactsb5/dataset.npz"
                    np.savez(dataset_path, X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test, X_train_pca=X_train_pca, X_test_pca=X_test_pca)
                    mlflow.log_artifact(dataset_path)

                    # Log ƒë·ªô ƒëo
                    if model_choice == "K-Means":
                        mlflow.log_metric("train_accuracy", train_accuracy)
                        mlflow.log_metric("test_accuracy", test_accuracy)
                    else:
                        mlflow.log_metric("n_clusters_train", n_clusters_train)
                        mlflow.log_metric("n_clusters_test", n_clusters_test)

                    # Log m√¥ h√¨nh
                    mlflow.sklearn.log_model(model, model_choice.lower())

                # Hi·ªÉn th·ªã link MLflow
                if "mlflow_url" in st.session_state and st.session_state.mlflow_initialized:
                    experiment_id = mlflow.get_experiment_by_name("Clustering").experiment_id
                    mlflow_link = f"{st.session_state.mlflow_url}/#/experiments/{experiment_id}/runs/{run_id}"
                    st.success(f"‚úÖ ƒê√£ log d·ªØ li·ªáu cho **Train_{st.session_state['run_name']}**!")
                    st.markdown(f"üîó [Truy c·∫≠p MLflow UI]({mlflow_link})")
                else:
                    st.info("üìù MLflow kh√¥ng kh·∫£ d·ª•ng tr√™n Streamlit Cloud. D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c log c·ª•c b·ªô.")
            except Exception as e:
                st.warning(f"‚ö†Ô∏è Kh√¥ng th·ªÉ log v√†o MLflow: {str(e)}. Hu·∫•n luy·ªán v·∫´n th√†nh c√¥ng nh∆∞ng kh√¥ng log l√™n DagsHub.")

            # L∆∞u m√¥ h√¨nh v√†o session_state
            if "models" not in st.session_state:
                st.session_state["models"] = []
            
            model_name = model_choice.lower().replace(" ", "_")
            if model_choice == "K-Means":
                model_name += f"_{n_clusters}"
            else:
                model_name += f"_eps{eps}_min{min_samples}"
            
            existing_model = next((item for item in st.session_state["models"] if item["name"] == model_name), None)
            if existing_model:
                count = 1
                new_model_name = f"{model_name}_{count}"
                while any(item["name"] == new_model_name for item in st.session_state["models"]):
                    count += 1
                    new_model_name = f"{model_name}_{count}"
                model_name = new_model_name
                st.warning(f"‚ö†Ô∏è M√¥ h√¨nh ƒë∆∞·ª£c l∆∞u v·ªõi t√™n m·ªõi: {model_name}")
            
            st.session_state["models"].append({"name": model_name, "model": model})
            st.write(f"üîπ M√¥ h√¨nh ƒë√£ ƒë∆∞·ª£c l∆∞u v·ªõi t√™n: {model_name}")
            st.write(f"T·ªïng s·ªë m√¥ h√¨nh hi·ªán t·∫°i: {len(st.session_state['models'])}")
            st.write("üìã Danh s√°ch c√°c m√¥ h√¨nh ƒë√£ l∆∞u:", ", ".join([m["name"] for m in st.session_state["models"]]))

from PIL import Image
import numpy as np

def preprocess_canvas_image(canvas_result):
    """X·ª≠ l√Ω h√¨nh ·∫£nh t·ª´ canvas th√†nh ƒë·ªãnh d·∫°ng ph√π h·ª£p v·ªõi MNIST (784 chi·ªÅu)."""
    if canvas_result.image_data is not None:
        try:
            # Chuy·ªÉn d·ªØ li·ªáu canvas th√†nh ·∫£nh PIL
            img = Image.fromarray(canvas_result.image_data.astype(np.uint8))
            # Chuy·ªÉn th√†nh grayscale
            img_gray = img.convert("L")
            # Resize v·ªÅ 28x28
            img_resized = img_gray.resize((28, 28), Image.Resampling.LANCZOS)
            # Chu·∫©n h√≥a v·ªÅ [0, 1]
            img_normalized = np.array(img_resized) / 255.0
            return img_normalized.reshape(1, -1)  # Tr·∫£ v·ªÅ (1, 784)
        except Exception as e:
            st.error(f"‚ö†Ô∏è L·ªói khi x·ª≠ l√Ω ·∫£nh t·ª´ canvas: {str(e)}")
            return None
    return None

from PIL import Image
import numpy as np

def preprocess_uploaded_image(uploaded_file):
    """X·ª≠ l√Ω ·∫£nh t·∫£i l√™n th√†nh ƒë·ªãnh d·∫°ng ph√π h·ª£p v·ªõi MNIST (784 chi·ªÅu)."""
    if uploaded_file is not None:
        try:
            # ƒê·ªçc ·∫£nh t·ª´ file t·∫£i l√™n
            img = Image.open(uploaded_file).convert("L")  # Chuy·ªÉn sang grayscale
            # Resize v·ªÅ 28x28
            img_resized = img.resize((28, 28), Image.Resampling.LANCZOS)
            # Chu·∫©n h√≥a v·ªÅ [0, 1]
            img_normalized = np.array(img_resized) / 255.0
            return img_normalized.reshape(1, -1)  # Tr·∫£ v·ªÅ (1, 784)
        except Exception as e:
            st.error(f"‚ö†Ô∏è L·ªói khi x·ª≠ l√Ω ·∫£nh t·∫£i l√™n: {str(e)}")
            return None
    return None

def demo():
    st.header("‚úçÔ∏è V·∫Ω s·ªë ho·∫∑c t·∫£i ·∫£nh ƒë·ªÉ d·ª± ƒëo√°n c·ª•m")
    
    if "models" not in st.session_state or not st.session_state["models"]:
        st.error("‚ö†Ô∏è Ch∆∞a c√≥ m√¥ h√¨nh n√†o ƒë∆∞·ª£c hu·∫•n luy·ªán! Vui l√≤ng hu·∫•n luy·ªán m√¥ h√¨nh trong tab 'Hu·∫•n luy·ªán' tr∆∞·ªõc.")
        return

    # Ch·ªçn m√¥ h√¨nh t·ª´ danh s√°ch ƒë√£ hu·∫•n luy·ªán
    model_names = [model["name"] for model in st.session_state["models"]]
    model_option = st.selectbox("üîç Ch·ªçn m√¥ h√¨nh ƒë√£ hu·∫•n luy·ªán:", model_names)
    model = next(model["model"] for model in st.session_state["models"] if model["name"] == model_option)

    # L·∫•y PCA t·ª´ session_state
    if "pca" not in st.session_state:
        st.error("‚ö†Ô∏è PCA ch∆∞a ƒë∆∞·ª£c kh·ªüi t·∫°o! Vui l√≤ng hu·∫•n luy·ªán m√¥ h√¨nh tr∆∞·ªõc.")
        return
    pca = st.session_state["pca"]

    # Ch·ªçn ph∆∞∆°ng th·ª©c nh·∫≠p li·ªáu
    input_method = st.selectbox("üìå Ch·ªçn ph∆∞∆°ng th·ª©c nh·∫≠p:", ["V·∫Ω s·ªë", "T·∫£i ·∫£nh"])

    if input_method == "V·∫Ω s·ªë":
        st.subheader("V·∫Ω s·ªë")
        if "key_value" not in st.session_state:
            st.session_state.key_value = str(random.randint(0, 1000000))
        if st.button("üîÑ T·∫£i l·∫°i n·∫øu kh√¥ng th·∫•y canvas"):
            st.session_state.key_value = str(random.randint(0, 1000000))
        canvas_result = st_canvas(
            fill_color="black",
            stroke_width=10,
            stroke_color="white",
            background_color="black",
            height=300,
            width=300,
            drawing_mode="freedraw",
            key=st.session_state.key_value,
            update_streamlit=True
        )
        input_data = preprocess_canvas_image(canvas_result)
        source = "v√πng v·∫Ω"
    else:  # T·∫£i ·∫£nh
        st.subheader("T·∫£i ·∫£nh")
        uploaded_file = st.file_uploader("Ch·ªçn ·∫£nh s·ªë (jpg, png)...", type=["jpg", "png"])
        input_data = preprocess_uploaded_image(uploaded_file)
        source = "·∫£nh t·∫£i l√™n"

    if st.button("D·ª± ƒëo√°n c·ª•m"):
        if input_data is not None:
            # Hi·ªÉn th·ªã ·∫£nh ƒë√£ x·ª≠ l√Ω
            st.image(
                Image.fromarray((input_data.reshape(28, 28) * 255).astype(np.uint8)),
                caption=f"·∫¢nh x·ª≠ l√Ω t·ª´ {source}",
                width=100
            )

            # Gi·∫£m chi·ªÅu d·ªØ li·ªáu ƒë·∫ßu v√†o t·ª´ 784 xu·ªëng 2 b·∫±ng PCA ƒë√£ fit
            input_data_pca = pca.transform(input_data)

            # D·ª± ƒëo√°n c·ª•m
            if isinstance(model, KMeans):
                cluster = model.predict(input_data_pca)[0]
                st.subheader(f"üî¢ C·ª•m d·ª± ƒëo√°n: {cluster}")
            elif isinstance(model, DBSCAN):
                cluster = model.fit_predict(input_data_pca)[0]
                st.subheader(f"üî¢ C·ª•m d·ª± ƒëo√°n: {cluster if cluster != -1 else 'Nhi·ªÖu (kh√¥ng thu·ªôc c·ª•m)'}")
            show_experiment_selector()    
        else:
          st.error(f"‚ö†Ô∏è H√£y {'v·∫Ω m·ªôt s·ªë' if input_method == 'V·∫Ω s·ªë' else 't·∫£i ·∫£nh'} tr∆∞·ªõc khi d·ª± ƒëo√°n!")
def show_experiment_selector():
    st.title(" MLflow Experiments ")
    experiment_name = "Clustering"
    experiments = mlflow.search_experiments()
    selected_experiment = next((exp for exp in experiments if exp.name == experiment_name), None)

    if not selected_experiment:
        st.error(f"‚ùå Experiment '{experiment_name}' kh√¥ng t·ªìn t·∫°i!")
        return

    st.subheader(f"üìå Experiment: {experiment_name}")
    st.write(f"**Experiment ID:** {selected_experiment.experiment_id}")
    st.write(f"**Tr·∫°ng th√°i:** {'Active' if selected_experiment.lifecycle_stage == 'active' else 'Deleted'}")

    runs = mlflow.search_runs(experiment_ids=[selected_experiment.experiment_id])
    if runs.empty:
        st.warning("‚ö† Kh√¥ng c√≥ runs n√†o trong experiment n√†y.")
        return

    st.write("### üèÉ‚Äç‚ôÇÔ∏è C√°c Runs g·∫ßn ƒë√¢y:")
    run_info = [(run["run_id"], run["params.run_name"] if "params.run_name" in run else f"Run {run['run_id'][:8]}") for _, run in runs.iterrows()]
    run_name_to_id = {name: rid for rid, name in run_info}
    selected_run_name = st.selectbox("üîç Ch·ªçn m·ªôt run:", list(run_name_to_id.keys()))
    selected_run_id = run_name_to_id[selected_run_name]

    selected_run = mlflow.get_run(selected_run_id)
    if selected_run:
        st.subheader(f"üìå Th√¥ng tin Run: {selected_run_name}")
        st.write(f"**Run ID:** {selected_run_id}")
        st.write(f"**Tr·∫°ng th√°i:** {selected_run.info.status}")
        start_time = datetime.fromtimestamp(selected_run.info.start_time / 1000).strftime("%Y-%m-%d %H:%M:%S") if selected_run.info.start_time else "Kh√¥ng c√≥ th√¥ng tin"
        st.write(f"**Th·ªùi gian ch·∫°y:** {start_time}")

        if selected_run.data.params:
            st.write("### ‚öôÔ∏è Parameters:")
            st.json(selected_run.data.params)
        if selected_run.data.metrics:
            st.write("### üìä Metrics:")
            st.json(selected_run.data.metrics)

def ly_thuyet_K_means():
    st.header("üìå L√Ω thuy·∫øt K-Means")
    st.write("""
    - **K-Means** l√† m·ªôt thu·∫≠t to√°n ph√¢n c·ª•m **kh√¥ng gi√°m s√°t** (unsupervised learning) nh·∫±m chia d·ªØ li·ªáu th√†nh **K c·ª•m** (clusters) d·ª±a tr√™n s·ª± t∆∞∆°ng ƒë·ªìng gi·ªØa c√°c ƒëi·ªÉm d·ªØ li·ªáu. Thu·∫≠t to√°n s·ª≠ d·ª•ng **kho·∫£ng c√°ch Euclidean** ƒë·ªÉ ƒëo l∆∞·ªùng s·ª± g·∫ßn g≈©i gi·ªØa c√°c ƒëi·ªÉm v√† t√¢m c·ª•m (centroids).
    """)

    st.subheader("üîç C√°ch ho·∫°t ƒë·ªông chi ti·∫øt")
    st.markdown("""
    Thu·∫≠t to√°n K-Means ho·∫°t ƒë·ªông qua c√°c b∆∞·ªõc l·∫∑p ƒëi l·∫∑p l·∫°i nh∆∞ sau:
    """)

    # S·ª≠ d·ª•ng expander ƒë·ªÉ hi·ªÉn th·ªã t·ª´ng b∆∞·ªõc chi ti·∫øt
    with st.expander("1. Kh·ªüi t·∫°o t√¢m c·ª•m (Initialization)"):
        st.markdown("""
        - Ch·ªçn ng·∫´u nhi√™n **K ƒëi·ªÉm** t·ª´ t·∫≠p d·ªØ li·ªáu l√†m **t√¢m c·ª•m ban ƒë·∫ßu** (centroids).  
        - **V√≠ d·ª•**: V·ªõi K = 3, ch·ªçn 3 ƒëi·ªÉm ng·∫´u nhi√™n t·ª´ t·∫≠p MNIST l√†m c√°c t√¢m c·ª•m kh·ªüi ƒë·∫ßu.
        """)

    with st.expander("2. G√°n nh√£n c·ª•m (Assignment Step)"):
        st.markdown("""
        - V·ªõi m·ªói ƒëi·ªÉm d·ªØ li·ªáu trong t·∫≠p, t√≠nh **kho·∫£ng c√°ch Euclidean** ƒë·∫øn t·∫•t c·∫£ c√°c t√¢m c·ª•m.  
        - G√°n ƒëi·ªÉm ƒë√≥ v√†o c·ª•m c√≥ t√¢m g·∫ßn nh·∫•t.  
        - **C√¥ng th·ª©c kho·∫£ng c√°ch Euclidean**:  
        """)
        st.latex(r"d(x, c) = \sqrt{\sum_{i=1}^{n} (x_i - c_i)^2}")
        st.markdown("""
        Trong ƒë√≥:  
        - \( x \): ƒêi·ªÉm d·ªØ li·ªáu.  
        - \( c \): T√¢m c·ª•m.  
        - \( n \): S·ªë chi·ªÅu c·ªßa d·ªØ li·ªáu (v·ªõi MNIST l√† 784).
        """)

    with st.expander("3. C·∫≠p nh·∫≠t t√¢m c·ª•m (Update Step)"):
        st.markdown("""
        - Sau khi g√°n t·∫•t c·∫£ ƒëi·ªÉm v√†o c√°c c·ª•m, t√≠nh l·∫°i **t√¢m c·ª•m m·ªõi** b·∫±ng c√°ch l·∫•y **trung b√¨nh t·ªça ƒë·ªô** c·ªßa m·ªçi ƒëi·ªÉm trong c·ª•m ƒë√≥.  
        - **C√¥ng th·ª©c**:  
        """)
        st.latex(r"c_j = \frac{1}{N_j} \sum_{x \in C_j} x")
        st.markdown("""
        Trong ƒë√≥:  
        - \( c_j \): T√¢m c·ª•m th·ª© \( j \).  
        - \( N_j \): S·ªë ƒëi·ªÉm trong c·ª•m \( j \).  
        - \( C_j \): T·∫≠p h·ª£p c√°c ƒëi·ªÉm thu·ªôc c·ª•m \( j \).
        """)

    with st.expander("4. L·∫∑p l·∫°i (Iteration)"):
        st.markdown("""
        - Quay l·∫°i b∆∞·ªõc 2, l·∫∑p l·∫°i qu√° tr√¨nh g√°n nh√£n v√† c·∫≠p nh·∫≠t t√¢m c·ª•m cho ƒë·∫øn khi:  
          - C√°c t√¢m c·ª•m kh√¥ng c√≤n thay ƒë·ªïi ƒë√°ng k·ªÉ (h·ªôi t·ª•).  
          - Ho·∫∑c ƒë·∫°t s·ªë l·∫ßn l·∫∑p t·ªëi ƒëa (max iterations).
        """)

    st.subheader("üí° V√≠ d·ª• v·ªõi MNIST")
    st.markdown("""
    - N·∫øu K = 10 (s·ªë ch·ªØ s·ªë t·ª´ 0-9), K-Means s·∫Ω c·ªë g·∫Øng nh√≥m c√°c ·∫£nh ch·ªØ s·ªë th√†nh 10 c·ª•m.  
    - Ban ƒë·∫ßu, ch·ªçn 10 ·∫£nh ng·∫´u nhi√™n l√†m t√¢m. Sau v√†i l·∫ßn l·∫∑p, c√°c t√¢m c·ª•m d·∫ßn ƒë·∫°i di·ªán cho c√°c nh√≥m ch·ªØ s·ªë (v√≠ d·ª•: c·ª•m 0 ch·ª©a h·∫ßu h·∫øt ·∫£nh s·ªë 0).
    """)


def ly_thuyet_DBSCAN():
    st.header("üìå L√Ω thuy·∫øt DBSCAN")
    st.write("""
    - **DBSCAN** (Density-Based Spatial Clustering of Applications with Noise) l√† m·ªôt thu·∫≠t to√°n ph√¢n c·ª•m **kh√¥ng gi√°m s√°t** d·ª±a tr√™n **m·∫≠t ƒë·ªô** c·ªßa c√°c ƒëi·ªÉm d·ªØ li·ªáu. 
    - Kh√°c v·ªõi K-Means, DBSCAN kh√¥ng y√™u c·∫ßu x√°c ƒë·ªãnh tr∆∞·ªõc s·ªë c·ª•m, m√† t·ª± ƒë·ªông t√¨m c√°c c·ª•m d·ª±a tr√™n ph√¢n b·ªë d·ªØ li·ªáu v√† c√≥ kh·∫£ nƒÉng ph√°t hi·ªán **nhi·ªÖu** (noise).
    """)

    st.subheader("üîç C√°ch ho·∫°t ƒë·ªông chi ti·∫øt")
    st.markdown("""
    DBSCAN ph√¢n c·ª•m d·ª±a tr√™n hai tham s·ªë ch√≠nh:  
    - **eps**: B√°n k√≠nh l√¢n c·∫≠n (kho·∫£ng c√°ch t·ªëi ƒëa gi·ªØa hai ƒëi·ªÉm ƒë·ªÉ coi l√† "g·∫ßn nhau").  
    - **min_samples**: S·ªë ƒëi·ªÉm t·ªëi thi·ªÉu trong v√πng l√¢n c·∫≠n ƒë·ªÉ h√¨nh th√†nh m·ªôt c·ª•m.  
    C√°c b∆∞·ªõc c·ª• th·ªÉ:
    """)

    # S·ª≠ d·ª•ng expander ƒë·ªÉ hi·ªÉn th·ªã t·ª´ng b∆∞·ªõc
    with st.expander("1. X√°c ƒë·ªãnh c√°c lo·∫°i ƒëi·ªÉm (Point Classification)"):
        st.markdown("""
        - **Core Point (ƒêi·ªÉm l√µi)**: M·ªôt ƒëi·ªÉm c√≥ √≠t nh·∫•t **min_samples** l√°ng gi·ªÅng (bao g·ªìm ch√≠nh n√≥) trong b√°n k√≠nh **eps**.  
        - **Border Point (ƒêi·ªÉm ranh gi·ªõi)**: Kh√¥ng ph·∫£i ƒëi·ªÉm l√µi, nh∆∞ng n·∫±m trong b√°n k√≠nh **eps** c·ªßa √≠t nh·∫•t m·ªôt ƒëi·ªÉm l√µi.  
        - **Noise Point (ƒêi·ªÉm nhi·ªÖu)**: Kh√¥ng ph·∫£i ƒëi·ªÉm l√µi, kh√¥ng n·∫±m trong b√°n k√≠nh **eps** c·ªßa b·∫•t k·ª≥ ƒëi·ªÉm l√µi n√†o.  
        - **V√≠ d·ª•**: V·ªõi MNIST, m·ªôt ƒëi·ªÉm l√µi c√≥ th·ªÉ l√† trung t√¢m c·ªßa v√πng ch·ªØ s·ªë "0", c√°c ƒëi·ªÉm ranh gi·ªõi l√† vi·ªÅn, v√† nhi·ªÖu l√† c√°c n√©t l·ªói.
        """)

    with st.expander("2. Kh·ªüi t·∫°o c·ª•m (Cluster Initialization)"):
        st.markdown("""
        - Ch·ªçn m·ªôt **ƒëi·ªÉm l√µi ch∆∞a thƒÉm** (unvisited core point) l√†m h·∫°t gi·ªëng (seed).  
        - T·∫°o c·ª•m m·ªõi t·ª´ ƒëi·ªÉm n√†y ƒë·ªÉ b·∫Øt ƒë·∫ßu qu√° tr√¨nh ph√¢n c·ª•m.
        """)

    with st.expander("3. M·ªü r·ªông c·ª•m (Cluster Expansion)"):
        st.markdown("""
        - Th√™m t·∫•t c·∫£ c√°c ƒëi·ªÉm trong b√°n k√≠nh **eps** c·ªßa ƒëi·ªÉm l√µi v√†o c·ª•m.  
        - N·∫øu m·ªôt ƒëi·ªÉm ƒë∆∞·ª£c th√™m l√† ƒëi·ªÉm l√µi, ti·∫øp t·ª•c m·ªü r·ªông c·ª•m t·ª´ ƒëi·ªÉm ƒë√≥ (ƒë·ªá quy).  
        - **C√¥ng th·ª©c kho·∫£ng c√°ch Euclidean**:  
        """)
        st.latex(r"d(x, y) = \sqrt{\sum_{i=1}^{n} (x_i - y_i)^2}")
        st.markdown("""
        Trong ƒë√≥:  
        - \( x, y \): Hai ƒëi·ªÉm d·ªØ li·ªáu.  
        - \( n \): S·ªë chi·ªÅu (784 v·ªõi MNIST).
        """)

    with st.expander("4. ƒê√°nh d·∫•u nhi·ªÖu v√† l·∫∑p l·∫°i"):
        st.markdown("""
        - C√°c ƒëi·ªÉm kh√¥ng thu·ªôc b·∫•t k·ª≥ c·ª•m n√†o ƒë∆∞·ª£c ƒë√°nh d·∫•u l√† **nhi·ªÖu**.  
        - Ch·ªçn ƒëi·ªÉm l√µi ch∆∞a thƒÉm ti·∫øp theo, l·∫∑p l·∫°i qu√° tr√¨nh cho ƒë·∫øn khi t·∫•t c·∫£ ƒëi·ªÉm ƒë∆∞·ª£c x·ª≠ l√Ω.
        """)

    st.subheader("üí° V√≠ d·ª• v·ªõi MNIST")
    st.markdown("""
    - N·∫øu **eps = 0.5** v√† **min_samples = 5**, DBSCAN c√≥ th·ªÉ:  
      - T√¨m c√°c c·ª•m d√†y ƒë·∫∑c (nh∆∞ v√πng ch·ªØ s·ªë gi·ªëng nhau, v√≠ d·ª•: c√°c ·∫£nh "1" th·∫≥ng ƒë·ª©ng).  
      - Lo·∫°i b·ªè c√°c n√©t v·∫Ω b·∫•t th∆∞·ªùng ho·∫∑c c√°c ·∫£nh kh√°c bi·ªát l·ªõn (nh∆∞ "1" nghi√™ng qu√° xa) l√†m nhi·ªÖu.  
    - K·∫øt qu·∫£: S·ªë c·ª•m kh√¥ng c·ªë ƒë·ªãnh, ph·ª• thu·ªôc v√†o m·∫≠t ƒë·ªô d·ªØ li·ªáu.
    """)

def main():
    st.title("üñäÔ∏è MNIST Clustering with Streamlit & MLflow")
    
    if "mlflow_initialized" not in st.session_state:
        mlflow.set_tracking_uri("https://dagshub.com/TonThatTruongVu/MNIST-ClusteringAlgorithms.mlflow")
        os.environ["MLFLOW_TRACKING_USERNAME"] = "TonThatTruongVu"
        os.environ["MLFLOW_TRACKING_PASSWORD"] = "519c4a864e131de52197f54d170c130beb15ffd5"
        
        try:
            mlflow.set_experiment("Clustering")
            st.session_state.mlflow_url = "https://dagshub.com/TonThatTruongVu/MNIST-ClusteringAlgorithms.mlflow"
            st.session_state.mlflow_initialized = True
        except Exception as e:
            st.error(f"‚ö†Ô∏è Kh√¥ng th·ªÉ k·∫øt n·ªëi MLflow: {str(e)}. MLflow s·∫Ω kh√¥ng ho·∫°t ƒë·ªông.")
            st.session_state.mlflow_initialized = False

    tabs = st.tabs(["L√Ω thuy·∫øt K-Means", "L√Ω thuy·∫øt DBSCAN", "Data", "Hu·∫•n luy·ªán", "D·ª± ƒëo√°n"])
    
    with tabs[0]:
        ly_thuyet_K_means()
    with tabs[1]:
        ly_thuyet_DBSCAN()
    with tabs[2]:
        data_processing()
    with tabs[3]:
        split_data()
        train_evaluate()
    with tabs[4]:
        demo()

if __name__ == "__main__":
    main()