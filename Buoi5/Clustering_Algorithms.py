import streamlit as st
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.datasets import fetch_openml
from sklearn.model_selection import train_test_split
from sklearn.cluster import KMeans, DBSCAN
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score
from streamlit_drawable_canvas import st_canvas
from PIL import Image
import mlflow
import os
import random
from datetime import datetime

# Táº£i dá»¯ liá»‡u MNIST tá»« OpenML
@st.cache_data
def load_mnist_data():
    X, y = fetch_openml('mnist_784', version=1, return_X_y=True, as_frame=False)
    X = X / 255.0  # Chuáº©n hÃ³a ngay khi táº£i
    return X, y.astype(int)

# Tab hiá»ƒn thá»‹ dá»¯ liá»‡u
def data_processing():
    st.header("ğŸ“˜ Dá»¯ Liá»‡u MNIST")
    X, y = load_mnist_data()
    
    st.write("""
        **ThÃ´ng tin táº­p dá»¯ liá»‡u MNIST:**
        - Tá»•ng sá»‘ máº«u: {}
        - KÃ­ch thÆ°á»›c má»—i áº£nh: 28 Ã— 28 pixels (784 Ä‘áº·c trÆ°ng)
        - Sá»‘ lá»›p: 10 (chá»¯ sá»‘ tá»« 0-9)
    """.format(X.shape[0]))

    st.subheader("Má»™t sá»‘ hÃ¬nh áº£nh máº«u")
    n_samples = 5
    fig, axes = plt.subplots(1, n_samples, figsize=(10, 3))
    indices = np.random.choice(X.shape[0], n_samples, replace=False)
    for i, idx in enumerate(indices):
        axes[i].imshow(X[idx].reshape(28, 28), cmap='gray')
        axes[i].set_title(f"Label: {y[idx]}")
        axes[i].axis("off")
    st.pyplot(fig)

# Tab chia dá»¯ liá»‡u
def split_data():
    st.title("ğŸ“Œ Chia dá»¯ liá»‡u Train/Test")
    X, y = load_mnist_data()
    total_samples = X.shape[0]

    if "data_split_done" not in st.session_state:
        st.session_state.data_split_done = False

    num_samples = st.slider("Chá»n sá»‘ lÆ°á»£ng áº£nh Ä‘á»ƒ train:", 1000, total_samples, 10000)
    test_size_percent = st.slider("Chá»n tá»· lá»‡ test (%):", 10, 50, 20)  # Äá»•i sang pháº§n trÄƒm
    test_size = test_size_percent / 100  # Chuyá»ƒn Ä‘á»•i sang dáº¡ng tháº­p phÃ¢n Ä‘á»ƒ sá»­ dá»¥ng trong train_test_split

    if st.button("âœ… XÃ¡c nháº­n & LÆ°u") and not st.session_state.data_split_done:
        st.session_state.data_split_done = True
        X_selected, _, y_selected, _ = train_test_split(X, y, train_size=num_samples, random_state=42)
        X_train, X_test, y_train, y_test = train_test_split(X_selected, y_selected, test_size=test_size, random_state=42)

        st.session_state.total_samples = num_samples
        st.session_state.X_train = X_train
        st.session_state.X_test = X_test
        st.session_state.y_train = y_train
        st.session_state.y_test = y_test
        st.session_state.train_size = X_train.shape[0]
        st.session_state.test_size = X_test.shape[0]

        summary_df = pd.DataFrame({
            "Táº­p dá»¯ liá»‡u": ["Train", "Test"],
            "Sá»‘ lÆ°á»£ng máº«u": [X_train.shape[0], X_test.shape[0]]
        })
        st.success(f"ğŸ”¹ Dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c chia: Train ({len(X_train)}), Test ({len(X_test)})")
        st.table(summary_df)

    elif st.session_state.data_split_done:
        st.info("âœ… Dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c chia, khÃ´ng cáº§n cháº¡y láº¡i.")
# Tab huáº¥n luyá»‡n vÃ  phÃ¢n cá»¥m

import streamlit as st
import numpy as np
from sklearn.cluster import KMeans, DBSCAN
from sklearn.metrics import accuracy_score
import mlflow
import mlflow.sklearn
import os

def train_evaluate():
    st.header("âš™ï¸ Chá»n mÃ´ hÃ¬nh & Huáº¥n luyá»‡n")
    
    if "X_train" not in st.session_state:
        st.error("âš ï¸ ChÆ°a cÃ³ dá»¯ liá»‡u! HÃ£y chia dá»¯ liá»‡u trÆ°á»›c.")
        return

    X_train = st.session_state.X_train
    y_train = st.session_state.y_train
    X_test = st.session_state.X_test
    y_test = st.session_state.y_test

    model_choice = st.selectbox("Chá»n mÃ´ hÃ¬nh:", ["K-Means", "DBSCAN"])
    
    if model_choice == "K-Means":
        st.markdown("""
        - **K-Means**: Thuáº­t toÃ¡n phÃ¢n cá»¥m chia dá»¯ liá»‡u thÃ nh K nhÃ³m dá»±a trÃªn khoáº£ng cÃ¡ch Euclidean.
        - **Tham sá»‘ cáº§n chá»n:**  
            - **Sá»‘ cá»¥m (K)**: Sá»‘ nhÃ³m mong muá»‘n.
        """)
        n_clusters = st.slider("Sá»‘ cá»¥m (K):", 2, 20, 10)
        model = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
        params = {"n_clusters": n_clusters}
    else:  # DBSCAN
        st.markdown("""
        - **DBSCAN**: Thuáº­t toÃ¡n phÃ¢n cá»¥m dá»±a trÃªn máº­t Ä‘á»™, khÃ´ng cáº§n xÃ¡c Ä‘á»‹nh sá»‘ cá»¥m trÆ°á»›c.
        - **Tham sá»‘ cáº§n chá»n:**
            - **eps**: BÃ¡n kÃ­nh lÃ¢n cáº­n Ä‘á»ƒ xÃ¡c Ä‘á»‹nh Ä‘iá»ƒm lÃ¡ng giá»ng.
            - **min_samples**: Sá»‘ Ä‘iá»ƒm tá»‘i thiá»ƒu Ä‘á»ƒ táº¡o thÃ nh cá»¥m.
        """)
        eps = st.slider("BÃ¡n kÃ­nh lÃ¢n cáº­n (eps):", 0.1, 10.0, 0.5, step=0.1)
        min_samples = st.slider("Sá»‘ Ä‘iá»ƒm tá»‘i thiá»ƒu:", 2, 20, 5)
        model = DBSCAN(eps=eps, min_samples=min_samples)
        params = {"eps": eps, "min_samples": min_samples}

    run_name = st.text_input("ğŸ”¹ Nháº­p tÃªn Run:", f"{model_choice}_Run")
    st.session_state["run_name"] = run_name if run_name else "default_run"
    
    if st.button("ğŸš€ Huáº¥n luyá»‡n mÃ´ hÃ¬nh"):
        st.write(f"â³ Äang huáº¥n luyá»‡n mÃ´ hÃ¬nh '{model_choice}'...")
        with st.spinner("Äang xá»­ lÃ½ dá»¯ liá»‡u vÃ  huáº¥n luyá»‡n..."):
            # ğŸ¯ **TÃ­ch há»£p MLflow**
            try:
                # Kiá»ƒm tra vÃ  táº¡o experiment náº¿u cáº§n
                experiment_name = "Clustering"
                experiment = mlflow.get_experiment_by_name(experiment_name)
                if experiment is None:
                    try:
                        experiment_id = mlflow.create_experiment(experiment_name)
                        st.info(f"âœ… ÄÃ£ táº¡o má»›i experiment '{experiment_name}' vá»›i ID: {experiment_id}")
                    except Exception as e:
                        st.warning(f"âš ï¸ KhÃ´ng thá»ƒ táº¡o experiment '{experiment_name}': {str(e)}. Sá»­ dá»¥ng experiment máº·c Ä‘á»‹nh (ID=0).")
                        experiment_id = "0"  # Fallback vá» experiment máº·c Ä‘á»‹nh tá»« link DagsHub
                else:
                    experiment_id = experiment.experiment_id

                with mlflow.start_run(run_name=f"Train_{st.session_state['run_name']}", experiment_id=experiment_id) as run:
                    run_id = run.info.run_id

                    # Log cÃ¡c tham sá»‘
                    mlflow.log_params({"model": model_choice, **params})
                    mlflow.log_param("train_size", X_train.shape[0])
                    mlflow.log_param("test_size", X_test.shape[0])
                    mlflow.log_param("total_samples", st.session_state.total_samples)

                    # LÆ°u dá»¯ liá»‡u táº¡m thá»i vÃ  log artifact
                    os.makedirs("mlflow_artifacts", exist_ok=True)
                    np.save("mlflow_artifacts/X_train.npy", X_train)
                    np.save("mlflow_artifacts/X_test.npy", X_test)
                    np.save("mlflow_artifacts/y_train.npy", y_train)
                    np.save("mlflow_artifacts/y_test.npy", y_test)
                    mlflow.log_artifacts("mlflow_artifacts")

                    # Huáº¥n luyá»‡n mÃ´ hÃ¬nh trÃªn dá»¯ liá»‡u gá»‘c 784 chiá»u
                    model.fit(X_train)
                    labels_train = model.labels_ if model_choice == "K-Means" else model.fit_predict(X_train)
                    
                    # ÄÃ¡nh giÃ¡ trÃªn táº­p train (chá»‰ cho K-Means)
                    if model_choice == "K-Means":
                        label_mapping = {}
                        for i in range(n_clusters):
                            mask = labels_train == i
                            if np.sum(mask) > 0:
                                most_common = np.bincount(y_train[mask].astype(int)).argmax()
                                label_mapping[i] = most_common
                        predicted_labels = np.array([label_mapping.get(label, 0) for label in labels_train])
                        train_accuracy = accuracy_score(y_train.astype(int), predicted_labels)
                        st.success(f"âœ… Äá»™ chÃ­nh xÃ¡c trÃªn táº­p train: {train_accuracy:.4f}")
                        mlflow.log_metric("train_accuracy", train_accuracy)

                    # ÄÃ¡nh giÃ¡ trÃªn táº­p test
                    labels_test = model.predict(X_test) if model_choice == "K-Means" else model.fit_predict(X_test)
                    if model_choice == "K-Means":
                        test_predicted_labels = np.array([label_mapping.get(label, 0) for label in labels_test])
                        test_accuracy = accuracy_score(y_test.astype(int), test_predicted_labels)
                        st.success(f"âœ… Äá»™ chÃ­nh xÃ¡c trÃªn táº­p test: {test_accuracy:.4f}")
                        mlflow.log_metric("test_accuracy", test_accuracy)

                    # Log mÃ´ hÃ¬nh
                    mlflow.sklearn.log_model(model, model_choice.lower())

            except Exception as e:
                st.error(f"âš ï¸ Lá»—i khi log vÃ o MLflow: {str(e)}. Huáº¥n luyá»‡n cá»¥c bá»™ hoÃ n táº¥t.")
                # Huáº¥n luyá»‡n cá»¥c bá»™ náº¿u MLflow lá»—i
                model.fit(X_train)
                labels_train = model.labels_ if model_choice == "K-Means" else model.fit_predict(X_train)
                if model_choice == "K-Means":
                    label_mapping = {}
                    for i in range(n_clusters):
                        mask = labels_train == i
                        if np.sum(mask) > 0:
                            most_common = np.bincount(y_train[mask].astype(int)).argmax()
                            label_mapping[i] = most_common
                    predicted_labels = np.array([label_mapping.get(label, 0) for label in labels_train])
                    train_accuracy = accuracy_score(y_train.astype(int), predicted_labels)
                    st.success(f"âœ… Äá»™ chÃ­nh xÃ¡c trÃªn táº­p train: {train_accuracy:.4f}")
                run_id = None

            # LÆ°u mÃ´ hÃ¬nh vÃ o session_state
            if "models" not in st.session_state:
                st.session_state["models"] = []
            
            model_name = model_choice.lower().replace(" ", "_")
            if model_choice == "K-Means":
                model_name += f"_{n_clusters}"
            else:
                model_name += f"_eps{eps}_min{min_samples}"
            
            existing_model = next((item for item in st.session_state["models"] if item["name"] == model_name), None)
            if existing_model:
                count = 1
                new_model_name = f"{model_name}_{count}"
                while any(item["name"] == new_model_name for item in st.session_state["models"]):
                    count += 1
                    new_model_name = f"{model_name}_{count}"
                model_name = new_model_name
                st.warning(f"âš ï¸ MÃ´ hÃ¬nh Ä‘Æ°á»£c lÆ°u vá»›i tÃªn má»›i: {model_name}")
            
            st.session_state["models"].append({"name": model_name, "model": model})
            st.write(f"ğŸ”¹ MÃ´ hÃ¬nh Ä‘Ã£ Ä‘Æ°á»£c lÆ°u vá»›i tÃªn: {model_name}")
            st.write(f"Tá»•ng sá»‘ mÃ´ hÃ¬nh hiá»‡n táº¡i: {len(st.session_state['models'])}")
            st.write("ğŸ“‹ Danh sÃ¡ch cÃ¡c mÃ´ hÃ¬nh Ä‘Ã£ lÆ°u:", ", ".join([m["name"] for m in st.session_state["models"]]))
            
            if run_id:  # Chá»‰ hiá»ƒn thá»‹ link náº¿u log thÃ nh cÃ´ng
                mlflow_tracking_uri = "https://dagshub.com/TonThatTruongVu/MNIST-ClusteringAlgorithms.mlflow"
                experiment_id = experiment_id if 'experiment_id' in locals() else "0"  # DÃ¹ng ID=0 náº¿u khÃ´ng cÃ³ experiment_id
                mlflow_link = f"{mlflow_tracking_uri}/#/experiments/{experiment_id}/runs/{run_id}"
                st.success(f"âœ… ÄÃ£ log dá»¯ liá»‡u cho 'Train_{st.session_state['run_name']}'!")
                st.markdown(f"ğŸ”— [Truy cáº­p MLflow UI]({mlflow_link})")
            else:
                st.info("ğŸ“ Huáº¥n luyá»‡n hoÃ n táº¥t nhÆ°ng khÃ´ng log MLflow do lá»—i káº¿t ná»‘i.")

from PIL import Image
import numpy as np

def preprocess_canvas_image(canvas_result):
    """Xá»­ lÃ½ hÃ¬nh áº£nh tá»« canvas thÃ nh Ä‘á»‹nh dáº¡ng phÃ¹ há»£p vá»›i MNIST (784 chiá»u)."""
    if canvas_result.image_data is not None:
        try:
            # Chuyá»ƒn dá»¯ liá»‡u canvas thÃ nh áº£nh PIL
            img = Image.fromarray(canvas_result.image_data.astype(np.uint8))
            # Chuyá»ƒn thÃ nh grayscale
            img_gray = img.convert("L")
            # Resize vá» 28x28
            img_resized = img_gray.resize((28, 28), Image.Resampling.LANCZOS)
            # Chuyá»ƒn thÃ nh máº£ng NumPy vÃ  chuáº©n hÃ³a vá» [0, 1]
            img_normalized = np.array(img_resized) / 255.0
            return img_normalized.reshape(1, -1)  # Reshape thÃ nh (1, 784)
        except Exception as e:
            st.error(f"âš ï¸ Lá»—i khi xá»­ lÃ½ áº£nh tá»« canvas: {str(e)}")
            return None
    return None

from PIL import Image
import numpy as np

def preprocess_uploaded_image(uploaded_file):
    """Xá»­ lÃ½ áº£nh táº£i lÃªn thÃ nh Ä‘á»‹nh dáº¡ng phÃ¹ há»£p vá»›i MNIST (784 chiá»u)."""
    if uploaded_file is not None:
        try:
            # Äá»c áº£nh tá»« file táº£i lÃªn
            img = Image.open(uploaded_file).convert("L")  # Chuyá»ƒn sang grayscale
            # Resize vá» 28x28
            img_resized = img.resize((28, 28), Image.Resampling.LANCZOS)
            # Chuyá»ƒn thÃ nh máº£ng NumPy vÃ  chuáº©n hÃ³a vá» [0, 1]
            img_normalized = np.array(img_resized) / 255.0
            return img_normalized.reshape(1, -1)  # Reshape thÃ nh (1, 784)
        except Exception as e:
            st.error(f"âš ï¸ Lá»—i khi xá»­ lÃ½ áº£nh táº£i lÃªn: {str(e)}")
            return None
    return None
def demo():
    st.header("âœï¸ Váº½ sá»‘ hoáº·c táº£i áº£nh Ä‘á»ƒ dá»± Ä‘oÃ¡n cá»¥m")

    # Kiá»ƒm tra xem cÃ³ mÃ´ hÃ¬nh nÃ o Ä‘Ã£ huáº¥n luyá»‡n chÆ°a
    if "models" not in st.session_state or not st.session_state["models"]:
        st.error("âš ï¸ MÃ´ hÃ¬nh chÆ°a Ä‘Æ°á»£c huáº¥n luyá»‡n! Vui lÃ²ng huáº¥n luyá»‡n mÃ´ hÃ¬nh trong tab 'Huáº¥n luyá»‡n & ÄÃ¡nh giÃ¡' trÆ°á»›c.")
        return

    # Dropdown chá»n mÃ´ hÃ¬nh Ä‘Ã£ huáº¥n luyá»‡n tá»« st.session_state["models"]
    st.subheader("ğŸ” Chá»n mÃ´ hÃ¬nh Ä‘Ã£ huáº¥n luyá»‡n")
    model_names = [model["name"] for model in st.session_state["models"]]
    model_option = st.selectbox("Chá»n mÃ´ hÃ¬nh:", model_names)
    model = next(model["model"] for model in st.session_state["models"] if model["name"] == model_option)

    # Chá»n phÆ°Æ¡ng thá»©c nháº­p liá»‡u
    input_method = st.selectbox("ğŸ“Œ Chá»n phÆ°Æ¡ng thá»©c nháº­p:", ["Váº½ sá»‘", "Táº£i áº£nh"])

    if input_method == "Váº½ sá»‘":
        st.subheader("Váº½ sá»‘")
        if "key_value" not in st.session_state:
            st.session_state.key_value = str(random.randint(0, 1000000))
        if st.button("ğŸ”„ Táº£i láº¡i náº¿u khÃ´ng tháº¥y canvas"):
            st.session_state.key_value = str(random.randint(0, 1000000))
        canvas_result = st_canvas(
            fill_color="black",
            stroke_width=10,
            stroke_color="white",
            background_color="black",
            height=300,
            width=300,
            drawing_mode="freedraw",
            key=st.session_state.key_value,
            update_streamlit=True
        )
        input_data = preprocess_canvas_image(canvas_result)
        source = "vÃ¹ng váº½"
    else:  # Táº£i áº£nh
        st.subheader("Táº£i áº£nh")
        uploaded_file = st.file_uploader("Chá»n áº£nh sá»‘ (jpg, png)...", type=["jpg", "png"])
        input_data = preprocess_uploaded_image(uploaded_file)
        source = "áº£nh táº£i lÃªn"

    if st.button("Dá»± Ä‘oÃ¡n cá»¥m"):
        if input_data is not None:
            # Hiá»ƒn thá»‹ áº£nh Ä‘Ã£ xá»­ lÃ½
            st.image(
                Image.fromarray((input_data.reshape(28, 28) * 255).astype(np.uint8)),
                caption=f"áº¢nh xá»­ lÃ½ tá»« {source}",
                width=100
            )

            # Dá»± Ä‘oÃ¡n cá»¥m trÃªn dá»¯ liá»‡u gá»‘c 784 chiá»u
            if isinstance(model, KMeans):
                cluster = model.predict(input_data)[0]
                st.subheader(f"ğŸ”¢ Cá»¥m dá»± Ä‘oÃ¡n: {cluster}")
            elif isinstance(model, DBSCAN):
                cluster = model.fit_predict(input_data)[0]
                st.subheader(f"ğŸ”¢ Cá»¥m dá»± Ä‘oÃ¡n: {cluster if cluster != -1 else 'Nhiá»…u (khÃ´ng thuá»™c cá»¥m)'}")
            show_experiment_selector()

        else:
            st.error(f"âš ï¸ HÃ£y {'váº½ má»™t sá»‘' if input_method == 'Váº½ sá»‘' else 'táº£i áº£nh'} trÆ°á»›c khi dá»± Ä‘oÃ¡n!")

def show_experiment_selector():
    st.title(" MLflow Experiments ")
    experiment_name = "Clustering"
    experiments = mlflow.search_experiments()
    selected_experiment = next((exp for exp in experiments if exp.name == experiment_name), None)

    if not selected_experiment:
        st.error(f"âŒ Experiment '{experiment_name}' khÃ´ng tá»“n táº¡i!")
        return

    st.subheader(f"ğŸ“Œ Experiment: {experiment_name}")
    st.write(f"**Experiment ID:** {selected_experiment.experiment_id}")
    st.write(f"**Tráº¡ng thÃ¡i:** {'Active' if selected_experiment.lifecycle_stage == 'active' else 'Deleted'}")

    runs = mlflow.search_runs(experiment_ids=[selected_experiment.experiment_id])
    if runs.empty:
        st.warning("âš  KhÃ´ng cÃ³ runs nÃ o trong experiment nÃ y.")
        return

    st.write("### ğŸƒâ€â™‚ï¸ CÃ¡c Runs gáº§n Ä‘Ã¢y:")
    run_info = [(run["run_id"], run["params.run_name"] if "params.run_name" in run else f"Run {run['run_id'][:8]}") for _, run in runs.iterrows()]
    run_name_to_id = {name: rid for rid, name in run_info}
    selected_run_name = st.selectbox("ğŸ” Chá»n má»™t run:", list(run_name_to_id.keys()))
    selected_run_id = run_name_to_id[selected_run_name]

    selected_run = mlflow.get_run(selected_run_id)
    if selected_run:
        st.subheader(f"ğŸ“Œ ThÃ´ng tin Run: {selected_run_name}")
        st.write(f"**Run ID:** {selected_run_id}")
        st.write(f"**Tráº¡ng thÃ¡i:** {selected_run.info.status}")
        start_time = datetime.fromtimestamp(selected_run.info.start_time / 1000).strftime("%Y-%m-%d %H:%M:%S") if selected_run.info.start_time else "KhÃ´ng cÃ³ thÃ´ng tin"
        st.write(f"**Thá»i gian cháº¡y:** {start_time}")

        if selected_run.data.params:
            st.write("### âš™ï¸ Parameters:")
            st.json(selected_run.data.params)
        if selected_run.data.metrics:
            st.write("### ğŸ“Š Metrics:")
            st.json(selected_run.data.metrics)

def ly_thuyet_K_means():
    st.header("ğŸ“Œ LÃ½ thuyáº¿t K-Means")
    st.write("""
    - **K-Means** lÃ  má»™t thuáº­t toÃ¡n phÃ¢n cá»¥m **khÃ´ng giÃ¡m sÃ¡t** (unsupervised learning) nháº±m chia dá»¯ liá»‡u thÃ nh **K cá»¥m** (clusters) dá»±a trÃªn sá»± tÆ°Æ¡ng Ä‘á»“ng giá»¯a cÃ¡c Ä‘iá»ƒm dá»¯ liá»‡u. Thuáº­t toÃ¡n sá»­ dá»¥ng **khoáº£ng cÃ¡ch Euclidean** Ä‘á»ƒ Ä‘o lÆ°á»ng sá»± gáº§n gÅ©i giá»¯a cÃ¡c Ä‘iá»ƒm vÃ  tÃ¢m cá»¥m (centroids).
    """)

    st.subheader("ğŸ” CÃ¡ch hoáº¡t Ä‘á»™ng chi tiáº¿t")
    st.markdown("""
    Thuáº­t toÃ¡n K-Means hoáº¡t Ä‘á»™ng qua cÃ¡c bÆ°á»›c láº·p Ä‘i láº·p láº¡i nhÆ° sau:
    """)

    # Sá»­ dá»¥ng expander Ä‘á»ƒ hiá»ƒn thá»‹ tá»«ng bÆ°á»›c chi tiáº¿t
    with st.expander("1. Khá»Ÿi táº¡o tÃ¢m cá»¥m (Initialization)"):
        st.markdown("""
        - Chá»n ngáº«u nhiÃªn **K Ä‘iá»ƒm** tá»« táº­p dá»¯ liá»‡u lÃ m **tÃ¢m cá»¥m ban Ä‘áº§u** (centroids).  
        - **VÃ­ dá»¥**: Vá»›i K = 3, chá»n 3 Ä‘iá»ƒm ngáº«u nhiÃªn tá»« táº­p MNIST lÃ m cÃ¡c tÃ¢m cá»¥m khá»Ÿi Ä‘áº§u.
        """)

    with st.expander("2. GÃ¡n nhÃ£n cá»¥m (Assignment Step)"):
        st.markdown("""
        - Vá»›i má»—i Ä‘iá»ƒm dá»¯ liá»‡u trong táº­p, tÃ­nh **khoáº£ng cÃ¡ch Euclidean** Ä‘áº¿n táº¥t cáº£ cÃ¡c tÃ¢m cá»¥m.  
        - GÃ¡n Ä‘iá»ƒm Ä‘Ã³ vÃ o cá»¥m cÃ³ tÃ¢m gáº§n nháº¥t.  
        - **CÃ´ng thá»©c khoáº£ng cÃ¡ch Euclidean**:  
        """)
        st.latex(r"d(x, c) = \sqrt{\sum_{i=1}^{n} (x_i - c_i)^2}")
        st.markdown("""
        Trong Ä‘Ã³:  
        - \( x \): Äiá»ƒm dá»¯ liá»‡u.  
        - \( c \): TÃ¢m cá»¥m.  
        - \( n \): Sá»‘ chiá»u cá»§a dá»¯ liá»‡u (vá»›i MNIST lÃ  784).
        """)

    with st.expander("3. Cáº­p nháº­t tÃ¢m cá»¥m (Update Step)"):
        st.markdown("""
        - Sau khi gÃ¡n táº¥t cáº£ Ä‘iá»ƒm vÃ o cÃ¡c cá»¥m, tÃ­nh láº¡i **tÃ¢m cá»¥m má»›i** báº±ng cÃ¡ch láº¥y **trung bÃ¬nh tá»a Ä‘á»™** cá»§a má»i Ä‘iá»ƒm trong cá»¥m Ä‘Ã³.  
        - **CÃ´ng thá»©c**:  
        """)
        st.latex(r"c_j = \frac{1}{N_j} \sum_{x \in C_j} x")
        st.markdown("""
        Trong Ä‘Ã³:  
        - \( c_j \): TÃ¢m cá»¥m thá»© \( j \).  
        - \( N_j \): Sá»‘ Ä‘iá»ƒm trong cá»¥m \( j \).  
        - \( C_j \): Táº­p há»£p cÃ¡c Ä‘iá»ƒm thuá»™c cá»¥m \( j \).
        """)

    with st.expander("4. Láº·p láº¡i (Iteration)"):
        st.markdown("""
        - Quay láº¡i bÆ°á»›c 2, láº·p láº¡i quÃ¡ trÃ¬nh gÃ¡n nhÃ£n vÃ  cáº­p nháº­t tÃ¢m cá»¥m cho Ä‘áº¿n khi:  
          - CÃ¡c tÃ¢m cá»¥m khÃ´ng cÃ²n thay Ä‘á»•i Ä‘Ã¡ng ká»ƒ (há»™i tá»¥).  
          - Hoáº·c Ä‘áº¡t sá»‘ láº§n láº·p tá»‘i Ä‘a (max iterations).
        """)

    st.subheader("ğŸ’¡ VÃ­ dá»¥ vá»›i MNIST")
    st.markdown("""
    - Náº¿u K = 10 (sá»‘ chá»¯ sá»‘ tá»« 0-9), K-Means sáº½ cá»‘ gáº¯ng nhÃ³m cÃ¡c áº£nh chá»¯ sá»‘ thÃ nh 10 cá»¥m.  
    - Ban Ä‘áº§u, chá»n 10 áº£nh ngáº«u nhiÃªn lÃ m tÃ¢m. Sau vÃ i láº§n láº·p, cÃ¡c tÃ¢m cá»¥m dáº§n Ä‘áº¡i diá»‡n cho cÃ¡c nhÃ³m chá»¯ sá»‘ (vÃ­ dá»¥: cá»¥m 0 chá»©a háº§u háº¿t áº£nh sá»‘ 0).
    """)


def ly_thuyet_DBSCAN():
    st.header("ğŸ“Œ LÃ½ thuyáº¿t DBSCAN")
    st.write("""
    - **DBSCAN** (Density-Based Spatial Clustering of Applications with Noise) lÃ  má»™t thuáº­t toÃ¡n phÃ¢n cá»¥m **khÃ´ng giÃ¡m sÃ¡t** dá»±a trÃªn **máº­t Ä‘á»™** cá»§a cÃ¡c Ä‘iá»ƒm dá»¯ liá»‡u. 
    - KhÃ¡c vá»›i K-Means, DBSCAN khÃ´ng yÃªu cáº§u xÃ¡c Ä‘á»‹nh trÆ°á»›c sá»‘ cá»¥m, mÃ  tá»± Ä‘á»™ng tÃ¬m cÃ¡c cá»¥m dá»±a trÃªn phÃ¢n bá»‘ dá»¯ liá»‡u vÃ  cÃ³ kháº£ nÄƒng phÃ¡t hiá»‡n **nhiá»…u** (noise).
    """)

    st.subheader("ğŸ” CÃ¡ch hoáº¡t Ä‘á»™ng chi tiáº¿t")
    st.markdown("""
    DBSCAN phÃ¢n cá»¥m dá»±a trÃªn hai tham sá»‘ chÃ­nh:  
    - **eps**: BÃ¡n kÃ­nh lÃ¢n cáº­n (khoáº£ng cÃ¡ch tá»‘i Ä‘a giá»¯a hai Ä‘iá»ƒm Ä‘á»ƒ coi lÃ  "gáº§n nhau").  
    - **min_samples**: Sá»‘ Ä‘iá»ƒm tá»‘i thiá»ƒu trong vÃ¹ng lÃ¢n cáº­n Ä‘á»ƒ hÃ¬nh thÃ nh má»™t cá»¥m.  
    CÃ¡c bÆ°á»›c cá»¥ thá»ƒ:
    """)

    # Sá»­ dá»¥ng expander Ä‘á»ƒ hiá»ƒn thá»‹ tá»«ng bÆ°á»›c
    with st.expander("1. XÃ¡c Ä‘á»‹nh cÃ¡c loáº¡i Ä‘iá»ƒm (Point Classification)"):
        st.markdown("""
        - **Core Point (Äiá»ƒm lÃµi)**: Má»™t Ä‘iá»ƒm cÃ³ Ã­t nháº¥t **min_samples** lÃ¡ng giá»ng (bao gá»“m chÃ­nh nÃ³) trong bÃ¡n kÃ­nh **eps**.  
        - **Border Point (Äiá»ƒm ranh giá»›i)**: KhÃ´ng pháº£i Ä‘iá»ƒm lÃµi, nhÆ°ng náº±m trong bÃ¡n kÃ­nh **eps** cá»§a Ã­t nháº¥t má»™t Ä‘iá»ƒm lÃµi.  
        - **Noise Point (Äiá»ƒm nhiá»…u)**: KhÃ´ng pháº£i Ä‘iá»ƒm lÃµi, khÃ´ng náº±m trong bÃ¡n kÃ­nh **eps** cá»§a báº¥t ká»³ Ä‘iá»ƒm lÃµi nÃ o.  
        - **VÃ­ dá»¥**: Vá»›i MNIST, má»™t Ä‘iá»ƒm lÃµi cÃ³ thá»ƒ lÃ  trung tÃ¢m cá»§a vÃ¹ng chá»¯ sá»‘ "0", cÃ¡c Ä‘iá»ƒm ranh giá»›i lÃ  viá»n, vÃ  nhiá»…u lÃ  cÃ¡c nÃ©t lá»—i.
        """)

    with st.expander("2. Khá»Ÿi táº¡o cá»¥m (Cluster Initialization)"):
        st.markdown("""
        - Chá»n má»™t **Ä‘iá»ƒm lÃµi chÆ°a thÄƒm** (unvisited core point) lÃ m háº¡t giá»‘ng (seed).  
        - Táº¡o cá»¥m má»›i tá»« Ä‘iá»ƒm nÃ y Ä‘á»ƒ báº¯t Ä‘áº§u quÃ¡ trÃ¬nh phÃ¢n cá»¥m.
        """)

    with st.expander("3. Má»Ÿ rá»™ng cá»¥m (Cluster Expansion)"):
        st.markdown("""
        - ThÃªm táº¥t cáº£ cÃ¡c Ä‘iá»ƒm trong bÃ¡n kÃ­nh **eps** cá»§a Ä‘iá»ƒm lÃµi vÃ o cá»¥m.  
        - Náº¿u má»™t Ä‘iá»ƒm Ä‘Æ°á»£c thÃªm lÃ  Ä‘iá»ƒm lÃµi, tiáº¿p tá»¥c má»Ÿ rá»™ng cá»¥m tá»« Ä‘iá»ƒm Ä‘Ã³ (Ä‘á»‡ quy).  
        - **CÃ´ng thá»©c khoáº£ng cÃ¡ch Euclidean**:  
        """)
        st.latex(r"d(x, y) = \sqrt{\sum_{i=1}^{n} (x_i - y_i)^2}")
        st.markdown("""
        Trong Ä‘Ã³:  
        - \( x, y \): Hai Ä‘iá»ƒm dá»¯ liá»‡u.  
        - \( n \): Sá»‘ chiá»u (784 vá»›i MNIST).
        """)

    with st.expander("4. ÄÃ¡nh dáº¥u nhiá»…u vÃ  láº·p láº¡i"):
        st.markdown("""
        - CÃ¡c Ä‘iá»ƒm khÃ´ng thuá»™c báº¥t ká»³ cá»¥m nÃ o Ä‘Æ°á»£c Ä‘Ã¡nh dáº¥u lÃ  **nhiá»…u**.  
        - Chá»n Ä‘iá»ƒm lÃµi chÆ°a thÄƒm tiáº¿p theo, láº·p láº¡i quÃ¡ trÃ¬nh cho Ä‘áº¿n khi táº¥t cáº£ Ä‘iá»ƒm Ä‘Æ°á»£c xá»­ lÃ½.
        """)

    st.subheader("ğŸ’¡ VÃ­ dá»¥ vá»›i MNIST")
    st.markdown("""
    - Náº¿u **eps = 0.5** vÃ  **min_samples = 5**, DBSCAN cÃ³ thá»ƒ:  
      - TÃ¬m cÃ¡c cá»¥m dÃ y Ä‘áº·c (nhÆ° vÃ¹ng chá»¯ sá»‘ giá»‘ng nhau, vÃ­ dá»¥: cÃ¡c áº£nh "1" tháº³ng Ä‘á»©ng).  
      - Loáº¡i bá» cÃ¡c nÃ©t váº½ báº¥t thÆ°á»ng hoáº·c cÃ¡c áº£nh khÃ¡c biá»‡t lá»›n (nhÆ° "1" nghiÃªng quÃ¡ xa) lÃ m nhiá»…u.  
    - Káº¿t quáº£: Sá»‘ cá»¥m khÃ´ng cá»‘ Ä‘á»‹nh, phá»¥ thuá»™c vÃ o máº­t Ä‘á»™ dá»¯ liá»‡u.
    """)

def main():
    st.title("ğŸ–Šï¸ MNIST Clustering with Streamlit & MLflow")
    
    if "mlflow_initialized" not in st.session_state:
        mlflow.set_tracking_uri("https://dagshub.com/TonThatTruongVu/MNIST-ClusteringAlgorithms.mlflow")
        os.environ["MLFLOW_TRACKING_USERNAME"] = "TonThatTruongVu"
        os.environ["MLFLOW_TRACKING_PASSWORD"] = "519c4a864e131de52197f54d170c130beb15ffd5"
        mlflow.set_experiment("Clustering")
        st.session_state.mlflow_url = "https://dagshub.com/TonThatTruongVu/MNIST-ClusteringAlgorithms.mlflow"
        st.session_state.mlflow_initialized = True

    tabs = st.tabs(["LÃ½ thuyáº¿t K-Means", "LÃ½ thuyáº¿t DBSCAN", "Data", "Huáº¥n luyá»‡n", "Dá»± Ä‘oÃ¡n"])
    
    with tabs[0]:
        ly_thuyet_K_means()
    with tabs[1]:
        ly_thuyet_DBSCAN()
    with tabs[2]:
        data_processing()
    with tabs[3]:
        split_data()
        train_evaluate()
    with tabs[4]:
        demo()

if __name__ == "__main__":
    main()